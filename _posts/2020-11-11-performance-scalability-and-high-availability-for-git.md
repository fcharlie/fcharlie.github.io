---
layout: post
title:  "性能，可扩展性和高可用 - 大型 Git 代码托管平台的关键问题"
date:   2020-11-11 20:00:00 +0800
published: false
categories: git
---

## 前情提要

在 2019 年我曾写过一篇 Git 代码托管平台相关的文章 - [《探讨 Git 代码托管平台的若干问题 - 2019 版》](https://forcemz.net/git/2019/10/01/ExploreSomeIssuesWithGitHost/)，从开始撰写技术博客以来，写过很多的 Git 相关的技术文章，但这一篇是对不同的 Git 代码托管平台做了个简单对比，然后介绍了 Git 托管平台相应的功能，涉及到 Git 代码托管平台的关键问题没有详细分析，随着认识的不断深入，撰写本文的时机已经成熟，在本文中，我将分析大型 Git 代码托管平台的关键问题，并尝试设计这些问题的解决方案。

## 关键问题的定义

对于分布式系统而言，**可扩展性**（也可称之为 **伸缩性**），**高可用**，**性能** 是制约平台发展的关键性问题，也就是说只有在解决这些问题后才能够支撑更大的用户规模，服务更多的用户，创造更多的社会价值，对于代码托管平台而言，这也是一个普适的道理。

系统具备**可扩展性**则意味着系统可以横向扩展，能够支撑更大的用户规模，存储更多的数据。  
系统支持**高可用**则意味着用户几乎能够随时访问系统，系统出现软硬件故障时依然能够继续给用户提供完整的或者有限的服务。  
提升系统的**性能**则有助于加快数据处理，提高用户的访问速度，改善用户操作体验。

## Git 的关键性能

Git 代码托管平台与常规的 Web 服务有着很大的不同，这也是我经常给一些客户，开发人员传递的信息。Git 代码托管平台与一般的 Web 服务不同的是，Git 需要非常多的计算资源和 IO 读写，一般而言其他的 Web 服务或许只有其中一项或者两项有较高的需求。另一方面，程序员善于利用各种软件自动化工具，Git 代码托管平台除了需要为自然用户提供服务之外还需要为这些*机器人*提供服务。如何在这么多的请求背景下改善用户体验，解决性能问题也成了重要问题。

### 优化压缩解压

要分析 Git 的性能问题，我们应当从 Git 的原理着手，首先我们知道 Git 通过快照的方式将用户的源代码，文本，图片等等文件纳入到版本控制当中，使用 deflate 压缩存储，用户需要读取文件时从磁盘中读取后通过 inflate（deflate）解压缩然后返回给用户读取（这里我们应该知道 git 使用标准的 [zlib](https://github.com/madler/zlib) 提供的 deflate 算法）。在这个前提下，我们可以确定一台配置确定的机器，解压文件的速度是有上限的， [zstd](https://github.com/facebook/zstd/) 项目做出过一个对比，不考虑到磁盘 IO，Core i9-9900K CPU @ 5.0GHz 提供的数据是：压缩 90 MB/s 解压	400 MB/s。当然如果磁盘的 IO 达不到这个速度，那么这一数据会更小。这一点会不会会不会影响代码托管平台？当然是会的，比如我们在页面上查看存储库的目录，文件，下载 raw，这就需要从存储库中读取压缩后的对象，然后解压，解压后通过网络返回给用户。另外，用户如果在线提交代码，压缩过程通常也会在服务器上发生，这必然会占用服务器较高的资源。这一问题如何优化？对于 raw 下载功能，我们可以引入缓存文件服务器，我们知道文件存在一个唯一的 SHA1 值，我们为每个项目创建一个缓存目录，在缓存目录中，通过文件的 SHA1 值即可获得已经解压的文件，很多一部分请求省去了解压，服务器的压力自然就小了。另外，我们还可以利用 SIMD 指令优化文件的压缩解压过程，而标准的 zlib 并未做到这一点，在 [dotnet](https://github.com/dotnet/runtime/tree/master/src/libraries/Native/Windows/clrcompression) 中就有专门针对 [Intel CPU SIMD 指令集优化版本](https://github.com/dotnet/runtime/tree/master/src/libraries/Native/Windows/clrcompression/zlib-intel)。另外还有 zlib 衍生项目 [zlib-ng](https://github.com/zlib-ng/zlib-ng) 也针对不同的 CPU 利用 SIMD 指令集优化，实际上这只需要我们重新构建 git 二进制即可。

### 解决拉取时的性能问题

Git 代码托管平台需要提供的核心能力至少包括推送和拉取，拉取代码包括 `git fetch` 和 `git clone`，我们只讨论简单的智能传输（smart）协议，不讨论 Wire（v2） 协议，以 git fetch（HTTP） 为例：

1.   客户端请求 `GET /path/repo.git/info/refs?service=git-upload-pack`
2.   服务端返回引用列表
3.   客户端按引用发送已存在的、需要的 commit 信息
4.   服务端按照所需、已存在的 commit 清点对象，打包返回给客户端

我们逐一分析，在这个过程中会存在哪些性能问题，当客户端需要服务端的引用列表时，服务端上的 git 要将存储库中的引用及其 commit 一一返回给客户端，我们知道，git 的引用存储在存储库的 `refs`目录下按文件存储，每一个引用对应一个文件，也可以打包存储到 `packed-refs` 中，如果存储库引用较少，分支较少，那么这通常不是问题，但是，如果存在一个像 Windows/Chrome 这样的项目，几万个分支，如果这些分支都未打包到 packed-refs，在服务发现的过程我们就会发现，[open()](https://linux.die.net/man/3/open) 系统调用就有几万个，几十上百个请求过来都是几百万的系统调用了，这还能不影响性能吗？解决这个问题的方法 git 早已经提供了，**packed-refs**，将引用打包存储到一个文件中，作为代码托管平台而言该怎么做呢？定期 GC，使引用被打包。 

如果引用数目较多，这也就意味着一次性传输的数据较多，但这些数据并不一定全部是用户需要的，引用发现还是一股脑的返回了。如何解决这个问题，2018 年 5 月 Git Wire Protocol 出现了，Wire 协议可以使用 ls-refs 命令获得仅需的引用信息。

在这个流程中，如果 git 存储库的对象比较多，那么清点对象的时间可能非常长，之前清点对象的原理如下：

1.   列出本地所有分支最新的一个commit
2.   列出远程所有分支最新的一个commit
3.   两者进行比较，只要有不同，就意味着分支发生变动
4.   每一个发生变动的commit，都清点其中具体变动的子目录和文件
5.   追溯到当前commit的父节点，重复第四步，直至本地与远程的历史一致为止
6.   加总所有需要变动的对象

早期清点 Linux 内核源码这样的仓库需要 8 分钟，这太慢了能解决吗？ Github 贡献了 [Git Bitmap](https://github.blog/2015-09-22-counting-objects/) 通过空间换时间解决了这个问题，具体的实现细节可以阅读相关博客和规范。对于代码托管平台而言，及时更新 Git，配置好 bitmap 配置 `repack.writeBitmaps=true` 通常能获得更好的体验。

### 缩短推送耗时

对于 Git 推送，目前依然使用的是智能传输协议，其流程如下：

1.   客户端请求 `GET /path/repo.git/info/refs?service=git-receive-pack`
2.   服务端返回引用列表及其他能力信息（包括原子更新等等）
3.   客户端清点打包需要上传的对象
4.   服务端接受对象包，解包，更新引用，返回更新结果。

随着用户需求的多样化，平台提供的特性越来越多，为了实现这类功能（比如针对 Git 做细粒度的权限控制，开发规范检查），我们通常是非侵入式的通过钩子实现，而通过钩子实现必然有一定的逻辑，这也会带来一定的时间消耗，比如，平台限制用户推送较大的文件，那么在钩子中就需要找出此次推送是否包含大文件，在之前的博客中，我就分享过如何优化钩子使其能够更快的找到大文件 [《Git 原生钩子的深度优化》](https://forcemz.net/git/2017/11/22/GitNativeHookDepthOptimization/)，这篇文章中还包含了钩子的其他场景优化。

### 其他场景的优化

有些平台，比如 Gitee 为企业级用户提供了存储库的快照功能，望文生义，快照就是每一次都做一次备份，那这么做会不会存在什么性能问题？如果每次都是全量的拉取存储库，大量数据带来的不仅仅是网络流量还有磁盘空间，CPU 时间消耗，因此在 2018 年，我就分享了 [《基于 Git Namespace 的存储库快照方案》](https://forcemz.net/git/2018/11/18/GitNamespaceSnapshot/)，通过名称空间变换实现 Git 存储库快照功能，通过优化极大的减少数据的传输。

比较两个存储库的数据是否一致，意味着它们拥有共同的对象，同样的引用，同样的 HEAD，但这种指标过于绝对，应当排除存储库中已经脱离版本控制的对象，如果存储库完整，我们只要一一比较存储库的引用是否一一对应且对象 ID 一致即可，如果我们需要跨机器比较，那么比较的市场一定和引用发现的时间和传输引用的时间相关，引用发现的时间不能缩短，那么我们可以优化引用传输的时间，我们通过在存储库中按照引用排序计算 BLAKE3 的哈希值，计算完毕后通过传输 BLAKE3 的哈希值比较两个存储库是否一致，这样就能优化存储库的比较。

### 性能优化的总结

针对 Git 代码托管平台的性能提升不是一蹴而就的，一定是一个一个的点啃出来的，只有一步一步，一点一点的进步，才能积累成巨大的进步。

## 解决平台的扩展性

与超级计算机相比，普通的计算机基本上是一个 CPU，内存大小较小，磁盘 IO 速度较低，而代码托管平台基本上是运行在这些普通计算机上的，这就意味着，从硬件层面来看，当计算机数量有限时，能够支撑的用户规模是有限的。而对于一个平台而言，如何基于整个平台实现其扩展性，为更多的用户提供服务，存储更多的存储库，这是实现大型 Git 代码托管平台的关键问题。

首先，服务器的存储是有限的，这一个问题毋庸置疑，随着硬件的不断发展，在代码托管平台中，我们可以为一台服务器挂载数 TB 的硬盘，更大的硬盘能够存储更多的内容，但是我们需要注意，硬盘的容量的价格曲线并不是线性的，因此，容量巨大的硬盘可能价格并不经济，另外单块硬盘的读写速度也是有限制的，因此早期，人们可以将多块硬盘挂载到一台机器以提高容量，但通常提高的容量比较有限。

### 分布式文件系统的歧途

人类的历史是螺旋发展的，有对的尝试也有错误的尝试，而代码托管的发展历史也是如此，现在我们谈论 Git 代码托管服务的可扩展性的时候，一般认为不建议使用分布式文件系统，要得出这个结论，开发者也在其中付出了很多的代价。2014 年，笔者加入开源中国，最初的工作是在 Git 代码托管平台实现兼容的 SVN 接入，彼时，为了支撑更多的存储库，当时的 Gitee（当时没有品牌，域名为： git.oschina.net）使用的是 NFS 将多台机器挂载到一台机器上，在这台机器上提供读写存储库的能力，按照现在的知识背景评价这种方案，我们能轻易的发现其中的问题：通过 NFS 读写文件的效率低于本机读写，NFS 存在缓存导致文件锁不能及时删除，git 的计算压力集中在 NFS client 端..... 当年的情况正是如此，后来为了解决这一问题，开发团队选择 ceph 文件系统替换 NFS. 这次变更堪称灾难性的，周末上线周一宕机，在海量 git 小文件面前，ceph 不堪一击。后来开发团队不得不回退到 NFS 方案，完全的架构变更则在我从完成 SVN 接入后才开始实施，后来通过两次分片策略的变更，若干个组件的研发，才成了今天中国第一大代码托管平台。虽然已经离开了 Gitee，但在 Gitee 做的工作还是非常有自豪感的。

### Git 的分片技术

要实现 Git 平台的可扩展，对资源进行合理的分片尤为重要，分片的方案很多，采用不同的分片方案往往与当时的技术背景相关，也与当时的认知背景相关，在 Gitee 最开始分片时，开发团队选择的是基于用户(Team)，也就是 `namespace`，这种策略的缺点很明显，创建仓库不能直接创建到空闲机器，负载并不均衡。后来 Gitee 切换到按照存储库分片，试图解决之前方案的不足，但由于历史包袱，这一过程持续了很长的时间。

我们在考虑 Git 的分片技术时，应该将存储库的真实路径与存储库 URL 分离，否则，在提供用户改名或者存储库改名，存储库转移的时候带来不必要的麻烦。

### 公共存储库的优化

公共 Git 代码托管平台很容易遇到一些热点问题，比如体积巨大的活跃存储库，在提供 fork 功能之后，这些存储库可能存在数量巨大的 fork 数。为了避免 fork 带来的海量存储问题，我们可以使用 git 的对象借用实现 fork 功能，以降低存储消耗。

当然**公共存储库的优化**是一个复杂的问题，在本文中就不再赘述了。

## 实现平台的高可用

大型的 Git 代码托管平台的一大挑战是实现平台的高可用，对于公有云而言，服务的高可用是平台的重要质量指标，服务稳定运行，故障较少，这也是用户优先选择的因素之一，而私有云客户在选择产品的时候同样会优先选择服务更稳定，拥有较好的高可用解决方案的厂商。

作为一个 Git 代码托管的资深业内人士，如果要选择一个职业上比较有成就感的事情，现在我可能会说是为前东家的 Gitee 设计和实现的 **Git 代码托管平台读写分离架构**。这一方案是目前比较经济划算的商用方案，据了解 Gitee 为了支持华为鸿蒙操作系统开源，专门将相应的存储库存储到读写分离机器组中，另外还有国内某大型国有银行内部使用了该方案实现其代码托管的高可用。

随着认识的不断深入，我对实现 Git 代码托管平台高可用的认知也不断加深，架构设计也有了新的想法，反思以往总总，放眼未来，旧的设计如下，新的模型如下：

### 基于事件驱动型读写分离

设计 Git 代码托管平台读写分离重要的几点是保证写入的唯一性，实现存储库一致性检测机制。核心原则是事件驱动，产生什么事件，执行匹配的操作。

### 强制一致性多写系统

基于事件驱动型读写分离的核心是要求写入的唯一性，但这对存储库原子写入的要求较高，虽然 Git 具备一定的容错能力。

```diff
diff --git a/builtin/receive-pack.c b/builtin/receive-pack.c
index bb9909c52e..bca3843f00 100644
--- a/builtin/receive-pack.c
+++ b/builtin/receive-pack.c
@@ -60,6 +60,7 @@ static int report_status;
 static int report_status_v2;
 static int use_sideband;
 static int use_atomic;
+static int use_balanced_atomic;
 static int use_push_options;
 static int quiet;
 static int prefer_ofs_delta = 1;
@@ -226,6 +227,11 @@ static int receive_pack_config(const char *var, const char *value, void *cb)
 		return 0;
 	}
 
+	if (strcmp(var, "receive.balancedatomic") == 0) {
+		use_balanced_atomic = git_config_bool(var, value);
+		return 0;
+	}
+
 	if (strcmp(var, "receive.advertisepushoptions") == 0) {
 		advertise_push_options = git_config_bool(var, value);
 		return 0;
@@ -1844,6 +1850,8 @@ static void execute_commands_atomic(struct command *commands,
 			goto failure;
 	}
 
+	// TODO: check balance-update hook
+
 	if (ref_transaction_commit(transaction, &err)) {
 		rp_error("%s", err.buf);
 		reported_error = "atomic transaction failed";
@@ -1951,7 +1959,7 @@ static void execute_commands(struct command *commands,
 			    (cmd->run_proc_receive || use_atomic))
 				cmd->error_string = "fail to run proc-receive hook";
 
-	if (use_atomic)
+	if (use_atomic || use_balanced_atomic)
 		execute_commands_atomic(commands, si);
 	else
 		execute_commands_non_atomic(commands, si);

```

分布式锁和分布式信号量是其中的关键环节。（基于强制同步的 Redis 也可以使用 Redis 读写锁和 Redis 实现的信号量机制）


## 用户代码的高可靠


## 研发困境

解决 Git 代码托管平台的关键问题通常有很多途径，但实际上，我们往往做不到那么好，比如公司在相关架构上投入的研发力量较小，并且过于追求进度而不考虑架构的长期演进，又或者不愿与参与到核心组件的贡献，比如我们在设计 Git 代码托管平台高可用时，缺乏研发力量和团队支持往往难以通过改进 Git 本身来实现，这实际上很难优雅的达到预期目标，相对而言 Github 通过参与 Git 贡献，自己维护分支，其 DGit(Spoke) 要做的更好，国内阿里巴巴实际上做的不错，参与了多个 Git 特性的实现（不包括本文设计的关键问题）。

## 思考
